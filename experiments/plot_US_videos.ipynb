{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set testing dataset seed to 0\n",
      "Set testing dataset seed to 0\n",
      "Set testing dataset seed to 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/vol/ideadata/ed52egek/conda/latecho/lib/python3.11/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/vol/ideadata/ed52egek/conda/latecho/lib/python3.11/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet50_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet50_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    }
   ],
   "source": [
    "mode = \"LS\" # LS or IS (latent/image)\n",
    "\n",
    "import torch\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "utils_path = os.path.abspath(os.path.join('../'))\n",
    "if utils_path not in sys.path:\n",
    "    sys.path.append(utils_path)\n",
    "from utils.notebookutils import SimaseUSLatentDataset,SimaseUSVideoDataset, SiameseNetwork, model_forward_to_corrcoeff,model_forward_to_pred, model_forward_to_bin_pred\n",
    "\n",
    "normalization =lambda x: (x  - x.min())/(x.max() - x.min()) * 2 - 1  # should be -1 to 1 due to way we trained the model\n",
    "\n",
    "#datasets\n",
    "if mode == \"LS\": \n",
    "    ds_test_dynamic = SimaseUSLatentDataset(phase=\"testing\", transform=normalization, latents_csv=\"/vol/ideadata/at70emic/projects/TMI23/data/diffusion/dynamic/FileList.csv\", training_latents_base_path=\"/vol/ideadata/at70emic/projects/TMI23/data/diffusion/dynamic/Latents\", in_memory=False, generator_seed=0)\n",
    "    ds_test_psax = SimaseUSLatentDataset(phase=\"testing\", transform=normalization, latents_csv= \"/vol/ideadata/at70emic/projects/TMI23/data/diffusion/PSAX/FileList.csv\", training_latents_base_path= \"/vol/ideadata/at70emic/projects/TMI23/data/diffusion/PSAX/Latents\", in_memory=False, generator_seed=0)\n",
    "    ds_test_a4c = SimaseUSLatentDataset(phase=\"testing\", transform=normalization, latents_csv=\"/vol/ideadata/at70emic/projects/TMI23/data/diffusion/A4C/FileList.csv\", training_latents_base_path= \"/vol/ideadata/at70emic/projects/TMI23/data/diffusion/A4C/Latents\", in_memory=False, generator_seed=0)\n",
    "else: \n",
    "\n",
    "    ds_test_dynamic = SimaseUSVideoDataset(phase=\"testing\", transform=normalization, latents_csv=\"/vol/ideadata/at70emic/datasets/EchoNet-Dynamic/FileList.csv\", training_latents_base_path= \"/vol/ideadata/at70emic/datasets/EchoNet-Dynamic/Videos\", in_memory=False, generator_seed=0)\n",
    "    ds_test_psax = SimaseUSVideoDataset(phase=\"testing\", transform=normalization, latents_csv= \"/vol/ideadata/at70emic/datasets/Echonet-Peds/PSAX/processed/FileList.csv\", training_latents_base_path= \"/vol/ideadata/at70emic/datasets/Echonet-Peds/PSAX/processed/Videos\", in_memory=False, generator_seed=0)\n",
    "    ds_test_a4c = SimaseUSVideoDataset(phase=\"testing\", transform=normalization, latents_csv=\"/vol/ideadata/at70emic/datasets/Echonet-Peds/A4C/processed/FileList.csv\", training_latents_base_path= \"/vol/ideadata/at70emic/datasets/Echonet-Peds/A4C/processed/Videos\", in_memory=False, generator_seed=0)\n",
    "\n",
    "datasets = {\"d\": ds_test_dynamic, \"p\": ds_test_psax, \"a\": ds_test_a4c}\n",
    "ds_name_to_name = {\"d\": \"Dynamic\", \"p\": \"PSAX\", \"a\": \"A4C\"}\n",
    "\n",
    "#load models\n",
    "models = {\"a\": None, \"d\": None, \"p\": None}\n",
    "for model_name, model_ending in zip([\"a\", \"d\", \"p\"], [\"a4c\", \"Dynamic\", \"psax\"]): \n",
    "    model_basepath = f\"/vol/ideadata/ed52egek/pycharm/privatis_us/archive/{model_ending}{mode}Best\"\n",
    "    with open(os.path.join(model_basepath, \"config.json\")) as config:\n",
    "        config = config.read()\n",
    "\n",
    "    # parse config\n",
    "    config = json.loads(config)\n",
    "    net = SiameseNetwork(network=config['siamese_architecture'], in_channels=config['n_channels'], n_features=config['n_features'])\n",
    "    net.eval()\n",
    "    net = net.cuda()\n",
    "    best_name = [x for x in os.listdir(model_basepath) if x.endswith(\"best_network.pth\")][0]\n",
    "    net.load_state_dict(torch.load(os.path.join(model_basepath, best_name)))\n",
    "    models[model_name] = net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms import Resize\n",
    "import torchvision\n",
    "from einops import rearrange\n",
    "from PIL import Image\n",
    "\n",
    "mode = \"LV\"\n",
    "rdm = torch.randn((3, 1, 5))\n",
    "for frame_num in range(5):\n",
    "    frame = ds_test_dynamic[0][frame_num*10]\n",
    "\n",
    "    if mode == \"RDM\": \n",
    "        frame = torch.randn((3, 112//8, 112//8))\n",
    "    if mode == \"LV\":\n",
    "        frame = rdm[:,:, torch.randperm(5)]# + 0.05 * torch.randn((3, 1, 5))\n",
    "\n",
    "    frame = ((frame + 1) * 127.5).to(torch.uint8)\n",
    "    if frame.size()[-1] != 112:\n",
    "        frame = Resize(112, interpolation=torchvision.transforms.InterpolationMode.NEAREST,)(frame)\n",
    "        #pass\n",
    "\n",
    "    image = Image.fromarray(rearrange(frame.numpy(), \"c h w -> h w c\"))\n",
    "    image.save(f\"USframe{frame_num}{mode}.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.8744, -1.4230,  0.1571]],\n",
       "\n",
       "        [[ 0.6223, -1.4236, -1.0518]],\n",
       "\n",
       "        [[ 0.2928, -0.6817,  1.0972]]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rdm[:,:, torch.randperm(len(rdm))]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
